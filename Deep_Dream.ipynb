{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation,Dropout, Input\n",
    "from keras.optimizers import SGD\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "\n",
    "from scipy.optimize import fmin_l_bfgs_b\n",
    "\n",
    "from keras.applications import vgg19\n",
    "from keras import utils as np_utils\n",
    "from keras import backend as K\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(275, 183)\n",
      "(183, 275, 3)\n"
     ]
    }
   ],
   "source": [
    "#uploading image \n",
    "from PIL import Image\n",
    "img= Image.open(\"Desktop/images.jpeg\")\n",
    "orignal_size= img.size\n",
    "print(orignal_size)\n",
    "img_width= orignal_size[0]\n",
    "img_height=orignal_size[1]\n",
    "image_size= (img_height, img_width, 3)\n",
    "print(image_size)\n",
    "#img = img.resize((299,299))\n",
    "#img.show()\n",
    "x= img_to_array(img)\n",
    "x = np.expand_dims(x, axis=0)\n",
    "x=x[:,:,:,::-1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.random((1, img_height, img_width, 3)) * 20 + 128.\n",
    "x= x.reshape((img_height, img_width, 3))\n",
    "temp= array_to_img(x)\n",
    "temp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Downloading VGGNET\n",
    "dream = Input(batch_shape=(1,)+image_size)\n",
    "model = vgg19.VGG19(input_tensor=dream, weights=\"imagenet\", include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (1, 183, 275, 3)          0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (1, 183, 275, 64)         1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (1, 183, 275, 64)         36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (1, 91, 137, 64)          0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (1, 91, 137, 128)         73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (1, 91, 137, 128)         147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (1, 45, 68, 128)          0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (1, 45, 68, 256)          295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (1, 45, 68, 256)          590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (1, 45, 68, 256)          590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (1, 45, 68, 256)          590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (1, 22, 34, 256)          0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (1, 22, 34, 512)          1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (1, 22, 34, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (1, 22, 34, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (1, 22, 34, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (1, 11, 17, 512)          0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (1, 11, 17, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (1, 11, 17, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (1, 11, 17, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (1, 11, 17, 512)          2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (1, 5, 8, 512)            0         \n",
      "=================================================================\n",
      "Total params: 20,024,384.0\n",
      "Trainable params: 20,024,384.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Choosing the layer for activation features \n",
    "settings = {\n",
    "    'features': {\n",
    "        'block3_conv4': 1.5,\n",
    "        'block4_conv2': 1.5,\n",
    "    },\n",
    "    'continuity': 0.1,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def continuity_loss(x):\n",
    "    a = K.square(x[:, :img_height-1, :img_width-1, :] -\n",
    "                 x[:, 1:, :img_width-1, :])\n",
    "    b = K.square(x[:, :img_height-1, :img_width-1, :] -\n",
    "                 x[:, :img_height-1, 1:, :])\n",
    "    return K.sum(K.pow(a+b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "K._LEARNING_PHASE = tf.constant(0)\n",
    "loss = K.variable(0)\n",
    "for layer_name in settings['features']:\n",
    "    coeff = settings['features'][layer_name]\n",
    "    layer_output = layer_dict[layer_name].output\n",
    "    shape= layer_output.shape\n",
    "    scaling = int(np.prod(shape))\n",
    "    loss+= coeff*K.sum(K.square(layer_output[:, 2:-2, 2:-2, :]))/scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss += settings['continuity'] * continuity_loss(dream) / (img_height*img_width*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grads = K.gradients(loss, dream)[0]\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "collecting_grad_and_loss = K.function([dream], [loss, grads])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def loss_and_grads(x):\n",
    "        outs = collecting_grad_and_loss(x)\n",
    "        loss_value = outs[0]\n",
    "        if len(outs[1:]) == 1:\n",
    "            grad_values = outs[1].flatten().astype('float64')\n",
    "        else:\n",
    "            grad_values = np.array(outs[1:]).flatten().astype('float64')\n",
    "        return loss_value, grad_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient ascent\n",
    "def gradient_ascent(x, iterations, step):\n",
    "    for i in range(iterations):\n",
    "        outs = loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[1]\n",
    "        if loss_value <=0:\n",
    "            break\n",
    "        print 'Loss value at', i, ':', loss_value\n",
    "        x += step * grad_values.reshape((1,img_height,img_width,3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value at 0 : 1.58512e+06\n",
      "Loss value at 1 : 1.61896e+06\n",
      "Loss value at 2 : 1.64742e+06\n",
      "Loss value at 3 : 1.6728e+06\n",
      "Loss value at 4 : 1.69856e+06\n",
      "Loss value at 5 : 1.7237e+06\n",
      "Loss value at 6 : 1.74857e+06\n",
      "Loss value at 7 : 1.77369e+06\n",
      "Loss value at 8 : 1.79846e+06\n",
      "Loss value at 9 : 1.82366e+06\n",
      "Loss value at 10 : 1.84882e+06\n",
      "Loss value at 11 : 1.87439e+06\n",
      "Loss value at 12 : 1.89995e+06\n",
      "Loss value at 13 : 1.92585e+06\n",
      "Loss value at 14 : 1.95164e+06\n",
      "Loss value at 15 : 1.97769e+06\n",
      "Loss value at 16 : 2.00371e+06\n",
      "Loss value at 17 : 2.0298e+06\n",
      "Loss value at 18 : 2.05601e+06\n",
      "Loss value at 19 : 2.08266e+06\n"
     ]
    }
   ],
   "source": [
    "result = gradient_ascent(x,iterations=20,step=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(183, 275, 3)"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= result.reshape((img_height, img_width, 3))\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y- y.mean()\n",
    "y /= (y.std() + 1e-5)\n",
    "y *= 0.1\n",
    "\n",
    "# clip to [0, 1]\n",
    "y += 0.5\n",
    "y = np.clip(y, 0, 1)\n",
    "\n",
    "y *= 255\n",
    "# convert BGR to RGB\n",
    "y = y[:, :, ::-1]\n",
    "y = np.clip(y, 0, 255).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2= array_to_img(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
